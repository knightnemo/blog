<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=55186&amp;path=blog/livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Machine Learning Series: 5.Hyperparameter Selection | Nemo&#39;s Blog</title>
<meta name="keywords" content="machine-learning, computer-science, optimization, math, artificial-intelligence, algorithm, random-process, multi-arm-bandit">
<meta name="description" content="This is the fifth article in the Machine Learning Series. It covers classic approaches to Hyperparameter Selection, including Bayesian Optimization, Gradient Optimization, Random Search, Multi-Arm Bandits and Neural Architecture Search.">
<meta name="author" content="Nemo">
<link rel="canonical" href="http://localhost:55186/blog/posts/ml5/">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<meta name="referrer" content="no-referrer-when-downgrade">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.861c79de57c9db7acb194fc40ad15b8fc78b954c4ce73dd6d09ff1b9ac5207f1.css" integrity="sha256-hhx53lfJ23rLGU/ECtFbj8eLlUxM5z3W0J/xuaxSB/E=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:55186/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:55186/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:55186/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:55186/blog/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:55186/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:55186/blog/posts/ml5/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
        ]
    });
});
</script>


<meta property="og:url" content="http://localhost:55186/blog/posts/ml5/">
  <meta property="og:site_name" content="Nemo&#39;s Blog">
  <meta property="og:title" content="Machine Learning Series: 5.Hyperparameter Selection">
  <meta property="og:description" content="This is the fifth article in the Machine Learning Series. It covers classic approaches to Hyperparameter Selection, including Bayesian Optimization, Gradient Optimization, Random Search, Multi-Arm Bandits and Neural Architecture Search.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-01-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-01-01T00:00:00+00:00">
    <meta property="article:tag" content="Machine-Learning">
    <meta property="article:tag" content="Computer-Science">
    <meta property="article:tag" content="Optimization">
    <meta property="article:tag" content="Math">
    <meta property="article:tag" content="Artificial-Intelligence">
    <meta property="article:tag" content="Algorithm">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning Series: 5.Hyperparameter Selection">
<meta name="twitter:description" content="This is the fifth article in the Machine Learning Series. It covers classic approaches to Hyperparameter Selection, including Bayesian Optimization, Gradient Optimization, Random Search, Multi-Arm Bandits and Neural Architecture Search.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:55186/blog/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Machine Learning Series: 5.Hyperparameter Selection",
      "item": "http://localhost:55186/blog/posts/ml5/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Machine Learning Series: 5.Hyperparameter Selection",
  "name": "Machine Learning Series: 5.Hyperparameter Selection",
  "description": "This is the fifth article in the Machine Learning Series. It covers classic approaches to Hyperparameter Selection, including Bayesian Optimization, Gradient Optimization, Random Search, Multi-Arm Bandits and Neural Architecture Search.",
  "keywords": [
    "machine-learning", "computer-science", "optimization", "math", "artificial-intelligence", "algorithm", "random-process", "multi-arm-bandit"
  ],
  "articleBody": "Motivation 调超参当然是一个痛苦的事情了，那么有没有什么办法来让我们少调一调呢？答案是有的，下面将介绍一些古人的智慧。\n但在开始之前，还是让我们用数学的语言表达一下超参选择是个什么样的问题吧：\n我们想要找到$f(x_ 1,⋯, x_ d )$的最小值点，其中$x_ i$代表超参可能是连续或者离散的：$x_ i\\in[a,b]$或者$x_ i \\in {0,1,2,…}$，我们只能通过查询单点处的函数值，没法获得1阶和2阶的梯度信息。\n而且，这个$f$很可能是一个没有太多好的性质的函数，比如不一定有convex的性质。我们希望找最小值的过程尽可能的sample-efficient,因为每一次实验都可能需要好几小时甚至天。\nBayesian Optimization 这个算法的high-level idea是这样的：\nStep 1: Assume a prior distribution for the loss function $f$. Step 2: Select new sample(s) that balances exploration and exploitation. Either the new sample(s) gives better result.Or gives more information about $f$. Step 3: Update prior with the new sample(s) using Bayes’ rule. Go to Step 2. 在这里，我们需要两个模型：\n代理模型（surrogate model）: 用于对目标函数进行建模。 采集函数（acquisition function）：用来平衡探索和利用，指导选择下一个采样点。 Gaussian Process 这里一般对于代理模型的建模，我们将高斯函数拓展到无穷维空间上去，其中每一个输入$x$都对应一个维度。通常假设每个维度的均值为 0（即$\\mathbb{E}[f(x_ i)]=0$），这样能简化模型。如果有先验知识，也可以设为非零的均值函数。两个输入点 $x_ i$和$x_ j$的相关性由核函数$\\mathbb{E}[f(x_ i)f(x_ j)]=K(x_ i,x_ j)$定义。这个核函数表达了我们对函数光滑性、相似性等性质的假设。\n经过一些数学，我们有如下结论：\n当给定 $m$ 个已有的观测点 $(x_ 1, y_ 1), \\cdots, (x_ m, y_ m)$ 时，我们有： $$ f(x) \\mid ((x_ 1, y_ 1), \\cdots, (x_ m, y_ m)) \\sim \\mathcal{N}\\left(k_ *^T \\Sigma^{-1} y, K(x, x) - k_ *^T \\Sigma^{-1} k_ *\\right)$$\n其中：\n$k_ * = [K(x_ 1, x), \\cdots, K(x_ m, x)]$ $y = (y_ 1, \\cdots, y_ m)$ $\\Sigma$ 是 $m \\times m$ 的协方差矩阵，由 $K(x_ i, x_ j)$ 组成 由此我们可以获得我们当前模型在特定输入下的输出的均值和方差，之后我们的采集函数可以通过对于计算例如期望改进（Expected Improvement, EI）在当前最优值的基础上寻找改进期望值。\n这个具体的过程鼠鼠我也不是很懂，放几个链接大家有兴趣看看去吧：\n链接1 链接2 看点visualization:\nGradient Optimization 对于连续的超参，我们可以通过梯度递降的方法来优化：\n我们考虑一个简单的例子，在线性回归中寻找学习率的最佳值。我们知道这个损失函数是：$$L(w)=\\frac{1}{2}\\sum_ {i=1}^n(w^T x-y)^2$$ 对于其参数$w$求梯度： $$\\nabla_ w L(w)=\\sum_ {i=1}^n(w^T x-y)x$$ 然后梯度递降： $$w_ 1=w_ 0-\\eta \\nabla_ w L(w_ 0)$$ $$w_ 2=w_ 1-\\eta \\nabla_ w L(w_ 1)$$ 那么我们想要求$\\nabla_ \\eta f(w_ 0,\\eta):=L(w_ 2)$，其实只用使用下链式法则： $$\\nabla_ \\eta f(w_ 0,\\eta)=\\nabla_ w L(w_ 2)\\cdot \\nabla_ \\eta w_ 2=\\sum_ {i=1}^n(w_ 2^T x-y)x \\cdot \\nabla_ \\eta w_ 2$$ 对于$\\nabla_ \\eta w_ 2$,我们继续求导： $$\\nabla_ \\eta w_ 2=\\nabla_ \\eta w_ 1-\\nabla_ w L(w_ 1)-\\eta \\nabla_ \\eta(\\nabla_ w L(w_ 1))$$ 然后接着顺着往下求。\nMemory Problem 刚才是naive的反向传播梯度的方法，但是这个会带来一个很显著的问题，就是对于计算$\\eta \\nabla_ \\eta \\nabla_ w L(w_ i),i=1,2,…,T$的梯度，我们假如将$w_ 1,…,w_ T$全部存入内存的话，内存是会爆炸的，因为太大了。那么，有什么办法解决吗？让我们对SGD with momentum的优化器进行分析：\n$v_ t$如何理解呢？$v_ t$可以理解为一个历史梯度状态的压缩(等比平均?)，因为当前的梯度的方差可能太大，所以有这样一种soft的更新方法有利于让优化过程更鲁棒的。而且收敛率也更快，$O(\\frac{1}{T^2})$快于SGD的$O(\\frac{1}{\\sqrt{T}})$.\n这里的核心出装在于： $$ v_ {t+1} = \\gamma v_ t - (1 - \\gamma) \\nabla_ w L(w_ t) $$\n$$ w_ {t+1} = w_ t + \\eta v_ {t+1} $$ 也就是说因为我只需要$w_ t$和$v_ t$,我们就可以左脚踩右脚，算出之前的$w_ i$和$v_ i$了，所以我们只需要存一对当前时刻的$w_ t$和$v_ t$即可了。\n听起来挺好的，但是因为这是计算机科学不是数学，我们存的数是会有精度损失的，也就是说因为$v_ t$的精度有限，所以其实还是会丢失一部分历史信息。而且这个问题不能忽略，因为误差累计是指数上涨的。那么怎么解决呢？\n我们可以用整数表达一切，在除什么的时候，将余数放入一个Buffer中，然后再乘回来的时候把这个余数加回来。\nComments: 这种方法只适用于连续的超参优化，而且优化过程也比较容易卡在local minima。\nRandom Search 顾名思义，就是对于可选的参数区间随机的取样。在实际中效果很好，比Grid Search（枚举所有可能）要样本利用率高很多。\nMulti-Arm Bandits Best Arm Identification 这里的多臂老虎机的目标和强化学习中比如UCB算法是不同的，对于UCB类的算法，他的目标是获得最高的累积回报，而在这里的setup是去找到最佳的老虎机。\n有$n$个臂，每次拉动一个臂时都会得到一个奖励，该奖励是一个具有期望值$v_ i$的有界随机变量。 每次选择一个臂并拉动时，会得到其奖励的一个独立样本。 在固定预算的情况下，我们如何找到期望值$v_ i$最大的臂？\nSuccessive Halving(SH) Algorithm 也就是说每一轮我们把预算平均分配给还存活的机器，然后计算获得的回报的均值，然后去掉回报小的那一半机器，再进入下一轮。下图为一示例：\nWLOG, 我们假设$v_ 1\u003ev_ 2\\geq…\\geq v_ n$,定义$\\Delta_ i=v_ 1-v_ i$.\nThm. With Probability $1-\\delta$, the algorithm finds the best arm with $$B = \\Theta\\left(H_ 2 \\log n \\log\\left(\\frac{\\log n}{\\delta}\\right)\\right)$$ arm pulls. $H_ 2=max_ {i\u003e1}\\frac{i}{\\Delta_ i^2}$.\n证明如下：\n如果第一个arm在第$r$轮之前没有被淘汰，那么对于任意不是arm 1的$i \\in S_ r$, 对于每一个arm有$\\frac{B}{|S_ r|log(n)}$的采样率，所以由Hoeffding Inequality:\n$$Pr[\\hat{v}_ 1^r\u003c\\hat{v}_ i^r]\\leq \\exp(-\\frac{1}{2}\\frac{B\\Delta^2_ i}{|S_ r|\\log(n)})$$\n令$n_ r=\\frac{n}{2^{r+2}}$,也就是说我们在round r把这些还存活的arm进行4等分。接下来我们把这个arm对应的真实值小的后3/4记为$S_ r’$,那么如果我们用$N_ r$记录$S_ r’$中在这一轮中的平均值大于arm1的arm的数量，有： $$\\mathbb{E}[N_ r]\\leq\\sum_ {i \\in S_ r’} \\exp(-\\frac{1}{2}\\frac{B\\Delta^2_ i}{|S_ r|\\log(n)})\\leq |S_ r’|\\exp(-\\frac{1}{8}\\frac{B\\Delta^2_ {n_ r}}{n_ r \\log(n)}) $$ 接着用Markov Inequality: $$Pr[N_ r\u003e\\frac{1}{3}|S_ r’|]\\leq 3 \\exp(-\\frac{1}{8}\\frac{B\\Delta^2_ {n_ r}}{n_ r \\log(n)})$$ 也就是说，有很高概率并没有那么多不那么好的机器的empirical mean比最好的机器的empirical mean大。\n最后，因为只有在后3/4中有至少1/3比arm 1大的时候，arm 1才有可能被淘汰，所以说arm 1在任意一轮被淘汰的概率最多是： $$3 \\sum_ {r=1}^{\\log n} \\exp(-\\frac{1}{8}\\frac{B\\Delta^2_ {n_ r}}{n_ r \\log(n)})\\leq 3 \\log(n) \\exp(-\\frac{B}{8 H_ 2 \\log(n)})$$ 这等价于 $$B = \\Omega\\left(H_ 2 \\log n \\log\\left(\\frac{\\log n}{\\delta}\\right)\\right)$$\nApplication to HyperParameter Tuning 在超参选择上，每一个超参的set都是一个arm，在初始阶段，我们随机选择许多配置。\n在setting上不太一样的点是：\n假设：可以观察到中间结果，能够在训练中途终止一些配置。\n操作：在训练过程中移除较不具前景的超参对应的实验。\n另一不一样的点是，我们并不是直接从随机变量中抽取样本，而是可以通过付出一定的代价来获得更加准确的观测值，这个代价就是更久的观察时间。最后观测到的值作为返回值。\n也就是说对于所有 $i \\in [n], k \\geq 1$，令 $\\ell_ {i,k} \\in \\mathbb{R}$ 为臂 $i$ 的一个序列，假设： $$ v_ i = \\lim_ {\\tau \\to \\infty} \\ell_ {i,\\tau} \\quad \\text{存在} $$ 那么对应的投入更多的budget就是对于运行更多的epoch数。\n一个实际运行的例子： 那么在这样的setting下有没有理论的保证呢？\n我们首先引入一些记号：\n$\\gamma_ i (t)$: 关于$t$单调不增，它给出了每个 $t$ 对应的最小值，使得： $$|\\ell_ {i,t} - v_ i| \\leq \\gamma_ i(t)$$ 也就是说它是曲线的“包络线”，表示当前观测值距离极限$v_ i$的接近程度。 $\\gamma_ i^{-1}(\\alpha) = \\min{t \\in \\mathbb{N}: \\gamma_ i(t) \\leq \\alpha}$ 表示首次进入与 $v_ i$ 的 $\\alpha$-邻域的时间点,值得注意的是，这里我们假设一旦我们进入，我们就再也不会出去了。 如果 $ k_ i \\geq \\gamma_ i^{-1}\\left(\\frac{v_ i - v_ 1}{2}\\right) $ 且 $ k_ 1 \\geq \\gamma_ 1^{-1}\\left(\\frac{v_ i - v_ 1}{2}\\right) $，则臂 $ i $ 和臂 $ 1 $ 可以被分开（即区分出优劣)。\nTheorem：\n令 $\\bar{\\gamma}(t) = \\max_ i \\gamma_ i(t)$，则有：$$B \\geq 2 \\log_ 2(n) \\left( n + \\sum_ {i=2,\\dots,n} \\bar{\\gamma}^{-1}\\left(\\frac{v_ i - v_ 1}{2}\\right) \\right)$$ 在以上条件下，SH算法能够返回最佳臂。\n证明如下：\n注意到： $$ B’ = 2 \\left( n + \\sum_ {i=2,\\dots,n} \\bar{\\gamma}^{-1} \\left( \\frac{v_ i - v_ 1}{2} \\right) \\right) $$\n每个臂被拉的次数为：$\\frac{B’}{|S_ r|}$,其中： $$ \\frac{B’}{|S_ r|} \u003e \\bar{\\gamma}^{-1} \\left( \\frac{v_ {\\lfloor\\frac{|S_ r|}{2}\\rfloor+1} - v_ 1}{2} \\right) $$ 这个结论是初等数学结论，读者不难自证。\n如果： $$ k_ i \\geq \\gamma_ i^{-1} \\left( \\frac{v_ i - v_ 1}{2} \\right), \\quad k_ 1 \\geq \\gamma_ 1^{-1} \\left( \\frac{v_ i - v_ 1}{2} \\right) $$ 那么臂 $i$ 和臂 $1$ 可以被区分开。\n因此，在第 $k$ 轮中，我们知道臂 $\\lfloor |S_ r| / 2 \\rfloor + 1$ 和臂 $1$ 已经被区分开。\n所以我们在$S_ {\\log_ 2(n)}$轮中就能够辨认最佳臂1了。\nNeural Architecture Search 这里的任务是Given a specific task. Find the best network structure for this task.\n一些成功的工作包括：\n强化学习 随机搜索 传统NAS算法需要大量的GPU计算资源。 通常只能用于一些代理任务（小规模/辅助任务）： 在小型数据集上训练。 使用少量的神经网络模块（blocks），仅训练几个epoch。 计算代价较低，但扩展到大规模任务时效果有限。 ProxyLess NAS 我们希望找到一个算法，使其能够适用于更大的任务。因此引入ProxylessNAS。\n方法：\n对于每一层（或边），考虑所有可能的结构 定义 $N$ 个组件 $o_ i$（例如不同的卷积滤波器大小、Identity层、池化层等） 联合训练结构（layer被选择的概率）与权重（内部的权重和偏置） 对于模型输出的类型，有如下三种方法：\nOne-shot方法（Bender et al., 2018）：\n输出为所有组件的加权和： $$ \\sum_ {i=1}^N o_ i(x) $$ 性能不足。 DARTS方法（Liu et al., 2018）：\n使用权重 $ \\alpha_ i $ 定义输出： $$ \\sum_ {i=1}^N p_ i o_ i(x), \\quad p_ i = \\frac{e^{\\alpha_ i}}{\\sum_ {j=1}^N e^{\\alpha_ j}} $$ 缺点：内存效率低，因为需要存储所有$N$条路径。最终模型只包含一条路径。 ProxylessNAS方法：\n二值化路径，定义布尔变量 $g$（一个one-hot向量）： $$ g = \\begin{cases} [1, 0, \\dots, 0], \u0026 \\text{概率为 } p_ 1 \\ \\vdots \\ [0, 0, \\dots, 1], \u0026 \\text{概率为 } p_ N \\end{cases} $$ 输出依赖于单一路径： $$ \\sum_ {i=1}^N g_ i o_ i(x) = \\begin{cases} o_ 1(x), \u0026 \\text{概率为 } p_ 1 \\ \\vdots \\ o_ N(x), \u0026 \\text{概率为 } p_ N \\end{cases} $$ 注：这里的$p_ {[1:N]}$是根据$\\alpha_ {[1:n]}$通过softmax采样得到的。 优势：大幅节省内存。只需存储单一路径，而不存储所有 (N) 条路径。 最后看一下训练过程：\n交替训练网络结构和权重：\n在训练权重时，冻结 $ \\alpha_ i $，并采样结构。 在训练 $ \\alpha_ i $ 时，冻结权重。 如何学习 $\\alpha_ i$：\n链式法则近似计算 $ \\frac{\\partial L}{\\partial \\alpha_ i} $： $$ \\frac{\\partial L}{\\partial \\alpha_ i} = \\sum_ {j=1}^N \\frac{\\partial L}{\\partial g_ j} \\frac{\\partial g_ j}{\\partial \\alpha_ i} \\approx \\sum_ {j=1}^N \\frac{\\partial L}{\\partial g_ j} \\frac{\\partial p_ j}{\\partial \\alpha_ i} $$ 其中： $$ \\frac{\\partial p_ j}{\\partial \\alpha_ i} = \\sum_ {j=1}^N \\delta_ {ij} p_ j (1 - p_ i) - p_ i p_ j $$ $ \\delta_ {ij} = 1 $ 如果 $ i = j $，否则为0。 更多的细节可以看一下原论文。 Misc 2025年了，祝大家新年快乐！\n至于认识我的朋友，解释下为什么今年没有发朋友圈，因为实在是没有太多值得说的东西，有很多under-construction的事情，所以，2025对我、也希望对大家，会是很让人兴奋的一年。 调超参是一个听起来很有趣但实际上大家都在做Graduate Student Search的领域，也希望在做AI相关领域科研的朋友能够在2025年有“金手指”，调参手到擒来！\n",
  "wordCount" : "870",
  "inLanguage": "en",
  "datePublished": "2025-01-01T00:00:00Z",
  "dateModified": "2025-01-01T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Nemo"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:55186/blog/posts/ml5/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Nemo's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:55186/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:55186/blog/" accesskey="h" title="Nemo&#39;s Blog (Alt + H)">Nemo&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:55186/blog/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:55186/blog/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:55186/blog/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:55186/blog/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:55186/blog/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://knightnemo.github.io" title="About Me">
                    <span>About Me</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:55186/blog/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:55186/blog/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Machine Learning Series: 5.Hyperparameter Selection
    </h1>
    <div class="post-meta"><span title='2025-01-01 00:00:00 +0000 UTC'>January 1, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Nemo


      <div  class="meta-item">&nbsp·&nbsp
        <span id="busuanzi_container_page_pv"> Reads: <span id="busuanzi_value_page_pv"></span> times</span>
      </div>
    </div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#motivation" aria-label="Motivation">Motivation</a></li>
                <li>
                    <a href="#bayesian-optimization" aria-label="Bayesian Optimization">Bayesian Optimization</a><ul>
                        
                <li>
                    <a href="#gaussian-process" aria-label="Gaussian Process">Gaussian Process</a></li></ul>
                </li>
                <li>
                    <a href="#gradient-optimization" aria-label="Gradient Optimization">Gradient Optimization</a><ul>
                        
                <li>
                    <a href="#memory-problem" aria-label="Memory Problem">Memory Problem</a></li></ul>
                </li>
                <li>
                    <a href="#random-search" aria-label="Random Search">Random Search</a></li>
                <li>
                    <a href="#multi-arm-bandits" aria-label="Multi-Arm Bandits">Multi-Arm Bandits</a><ul>
                        
                <li>
                    <a href="#best-arm-identification" aria-label="Best Arm Identification">Best Arm Identification</a></li>
                <li>
                    <a href="#successive-halvingsh-algorithm" aria-label="Successive Halving(SH) Algorithm">Successive Halving(SH) Algorithm</a></li>
                <li>
                    <a href="#application-to-hyperparameter-tuning" aria-label="Application to HyperParameter Tuning">Application to HyperParameter Tuning</a></li></ul>
                </li>
                <li>
                    <a href="#neural-architecture-search" aria-label="Neural Architecture Search">Neural Architecture Search</a><ul>
                        
                <li>
                    <a href="#proxyless-nas" aria-label="ProxyLess NAS">ProxyLess NAS</a></li></ul>
                </li>
                <li>
                    <a href="#misc" aria-label="Misc">Misc</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="motivation">Motivation<a hidden class="anchor" aria-hidden="true" href="#motivation">#</a></h2>
<p>调超参当然是一个痛苦的事情了，那么有没有什么办法来让我们少调一调呢？答案是有的，下面将介绍一些古人的智慧。</p>
<p>但在开始之前，还是让我们用数学的语言表达一下超参选择是个什么样的问题吧：</p>
<p>我们想要找到$f(x_ 1,⋯, x_ d )$的最小值点，其中$x_ i$代表超参可能是连续或者离散的：$x_ i\in[a,b]$或者$x_ i \in {0,1,2,&hellip;}$，我们只能通过查询单点处的函数值，没法获得1阶和2阶的梯度信息。</p>
<p>而且，这个$f$很可能是一个没有太多好的性质的函数，比如不一定有convex的性质。我们希望找最小值的过程尽可能的sample-efficient,因为每一次实验都可能需要好几小时甚至天。</p>
<h2 id="bayesian-optimization">Bayesian Optimization<a hidden class="anchor" aria-hidden="true" href="#bayesian-optimization">#</a></h2>
<p>这个算法的high-level idea是这样的：</p>
<blockquote>
<ul>
<li><strong>Step 1</strong>: Assume a prior distribution for the loss function $f$.</li>
<li><strong>Step 2</strong>: Select new sample(s) that balances exploration and exploitation. Either the new sample(s) gives better result.Or gives more information about $f$.</li>
<li><strong>Step 3</strong>: Update prior with the new sample(s) using Bayes&rsquo; rule. Go to Step 2.</li>
</ul>
</blockquote>
<p>在这里，我们需要两个模型：</p>
<ul>
<li><strong>代理模型（surrogate model）</strong>: 用于对目标函数进行建模。</li>
<li><strong>采集函数（acquisition function）</strong>：用来平衡探索和利用，指导选择下一个采样点。</li>
</ul>
<h3 id="gaussian-process">Gaussian Process<a hidden class="anchor" aria-hidden="true" href="#gaussian-process">#</a></h3>
<p>这里一般对于代理模型的建模，我们将高斯函数拓展到无穷维空间上去，其中每一个输入$x$都对应一个维度。通常假设每个维度的均值为 0（即$\mathbb{E}[f(x_ i)]=0$），这样能简化模型。如果有先验知识，也可以设为非零的均值函数。两个输入点 $x_ i$和$x_ j$的相关性由核函数$\mathbb{E}[f(x_ i)f(x_ j)]=K(x_ i,x_ j)$定义。这个核函数表达了我们对函数光滑性、相似性等性质的假设。</p>
<p>经过一些数学，我们有如下结论：</p>
<ul>
<li>
<p>当给定 $m$ 个已有的观测点 $(x_ 1, y_ 1), \cdots, (x_ m, y_ m)$ 时，我们有：
$$
f(x) \mid ((x_ 1, y_ 1), \cdots, (x_ m, y_ m)) \sim \mathcal{N}\left(k_ *^T \Sigma^{-1} y, K(x, x) - k_ *^T \Sigma^{-1} k_ *\right)$$</p>
</li>
<li>
<p>其中：</p>
<ul>
<li>$k_ * = [K(x_ 1, x), \cdots, K(x_ m, x)]$</li>
<li>$y = (y_ 1, \cdots, y_ m)$</li>
<li>$\Sigma$ 是 $m \times m$ 的协方差矩阵，由 $K(x_ i, x_ j)$ 组成</li>
</ul>
</li>
</ul>
<p>由此我们可以获得我们当前模型在特定输入下的输出的均值和方差，之后我们的采集函数可以通过对于计算例如期望改进（Expected Improvement, EI）在当前最优值的基础上寻找改进期望值。</p>
<p>这个具体的过程鼠鼠我也不是很懂，放几个链接大家有兴趣看看去吧：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/349600542">链接1</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/358606341">链接2</a></li>
</ul>
<p>看点visualization:</p>
<p><img loading="lazy" src="../img/ml5/image1.png#center"></p>
<p><img loading="lazy" src="../img/ml5/image2.png#center"></p>
<p><img loading="lazy" src="../img/ml5/image3.png#center"></p>
<p><img loading="lazy" src="../img/ml5/image4.png#center"></p>
<p><img loading="lazy" src="../img/ml5/image5.png#center"></p>
<p><img loading="lazy" src="../img/ml5/image6.png#center"></p>
<p><img loading="lazy" src="../img/ml5/image7.png#center"></p>
<h2 id="gradient-optimization">Gradient Optimization<a hidden class="anchor" aria-hidden="true" href="#gradient-optimization">#</a></h2>
<p>对于连续的超参，我们可以通过梯度递降的方法来优化：</p>
<p><img loading="lazy" src="../img/ml5/image8.png#center"></p>
<p>我们考虑一个简单的例子，在线性回归中寻找学习率的最佳值。我们知道这个损失函数是：$$L(w)=\frac{1}{2}\sum_ {i=1}^n(w^T x-y)^2$$
对于其参数$w$求梯度：
$$\nabla_ w L(w)=\sum_ {i=1}^n(w^T x-y)x$$
然后梯度递降：
$$w_ 1=w_ 0-\eta \nabla_ w L(w_ 0)$$
$$w_ 2=w_ 1-\eta \nabla_ w L(w_ 1)$$
那么我们想要求$\nabla_ \eta f(w_ 0,\eta):=L(w_ 2)$，其实只用使用下链式法则：
$$\nabla_ \eta f(w_ 0,\eta)=\nabla_ w L(w_ 2)\cdot \nabla_ \eta w_ 2=\sum_ {i=1}^n(w_ 2^T x-y)x \cdot \nabla_ \eta w_ 2$$
对于$\nabla_ \eta w_ 2$,我们继续求导：
$$\nabla_ \eta w_ 2=\nabla_ \eta w_ 1-\nabla_ w L(w_ 1)-\eta \nabla_ \eta(\nabla_ w L(w_ 1))$$
然后接着顺着往下求。</p>
<h3 id="memory-problem">Memory Problem<a hidden class="anchor" aria-hidden="true" href="#memory-problem">#</a></h3>
<p>刚才是naive的反向传播梯度的方法，但是这个会带来一个很显著的问题，就是对于计算$\eta \nabla_ \eta \nabla_ w L(w_ i),i=1,2,&hellip;,T$的梯度，我们假如将$w_ 1,&hellip;,w_ T$全部存入内存的话，内存是会爆炸的，因为太大了。那么，有什么办法解决吗？让我们对SGD with momentum的优化器进行分析：</p>
<p><img loading="lazy" src="../img/ml5/image9.png#center">
$v_ t$如何理解呢？$v_ t$可以理解为一个历史梯度状态的压缩(等比平均?)，因为当前的梯度的方差可能太大，所以有这样一种soft的更新方法有利于让优化过程更鲁棒的。而且收敛率也更快，$O(\frac{1}{T^2})$快于SGD的$O(\frac{1}{\sqrt{T}})$.</p>
<p>这里的核心出装在于：
$$
v_ {t+1} = \gamma v_ t - (1 - \gamma) \nabla_ w L(w_ t)
$$</p>
<p>$$
w_ {t+1} = w_ t + \eta v_ {t+1}
$$
也就是说因为我只需要$w_ t$和$v_ t$,我们就可以左脚踩右脚，算出之前的$w_ i$和$v_ i$了，所以我们只需要存一对当前时刻的$w_ t$和$v_ t$即可了。</p>
<p><img loading="lazy" src="../img/ml5/image10.png#center"></p>
<p>听起来挺好的，但是因为这是计算机科学不是数学，我们存的数是会有精度损失的，也就是说因为$v_ t$的精度有限，所以其实还是会丢失一部分历史信息。而且这个问题不能忽略，因为误差累计是指数上涨的。那么怎么解决呢？</p>
<p>我们可以用整数表达一切，在除什么的时候，将余数放入一个Buffer中，然后再乘回来的时候把这个余数加回来。</p>
<p>Comments: 这种方法只适用于连续的超参优化，而且优化过程也比较容易卡在local minima。</p>
<h2 id="random-search">Random Search<a hidden class="anchor" aria-hidden="true" href="#random-search">#</a></h2>
<p>顾名思义，就是对于可选的参数区间随机的取样。在实际中效果很好，比Grid Search（枚举所有可能）要样本利用率高很多。</p>
<h2 id="multi-arm-bandits">Multi-Arm Bandits<a hidden class="anchor" aria-hidden="true" href="#multi-arm-bandits">#</a></h2>
<h3 id="best-arm-identification">Best Arm Identification<a hidden class="anchor" aria-hidden="true" href="#best-arm-identification">#</a></h3>
<p>这里的多臂老虎机的目标和强化学习中比如UCB算法是不同的，对于UCB类的算法，他的目标是获得最高的累积回报，而在这里的setup是去找到最佳的老虎机。</p>
<p>有$n$个臂，每次拉动一个臂时都会得到一个奖励，该奖励是一个具有期望值$v_ i$的有界随机变量。
每次选择一个臂并拉动时，会得到其奖励的一个独立样本。
在固定预算的情况下，我们如何找到期望值$v_ i$最大的臂？</p>
<h3 id="successive-halvingsh-algorithm">Successive Halving(SH) Algorithm<a hidden class="anchor" aria-hidden="true" href="#successive-halvingsh-algorithm">#</a></h3>
<p><img loading="lazy" src="../img/ml5/image11.png#center">
也就是说每一轮我们把预算平均分配给还存活的机器，然后计算获得的回报的均值，然后去掉回报小的那一半机器，再进入下一轮。下图为一示例：</p>
<p><img loading="lazy" src="../img/ml5/image12.png#center"></p>
<p>WLOG, 我们假设$v_ 1&gt;v_ 2\geq&hellip;\geq v_ n$,定义$\Delta_ i=v_ 1-v_ i$.</p>
<blockquote>
<p><strong>Thm.</strong> With Probability $1-\delta$, the algorithm finds the best arm with
$$B = \Theta\left(H_ 2 \log n \log\left(\frac{\log n}{\delta}\right)\right)$$
arm pulls. $H_ 2=max_ {i&gt;1}\frac{i}{\Delta_ i^2}$.</p>
</blockquote>
<p>证明如下：</p>
<p>如果第一个arm在第$r$轮之前没有被淘汰，那么对于任意不是arm 1的$i \in S_ r$, 对于每一个arm有$\frac{B}{|S_ r|log(n)}$的采样率，所以由Hoeffding Inequality:</p>
<p>$$Pr[\hat{v}_ 1^r&lt;\hat{v}_ i^r]\leq \exp(-\frac{1}{2}\frac{B\Delta^2_ i}{|S_ r|\log(n)})$$</p>
<p>令$n_ r=\frac{n}{2^{r+2}}$,也就是说我们在round r把这些还存活的arm进行4等分。接下来我们把这个arm对应的真实值小的后3/4记为$S_ r&rsquo;$,那么如果我们用$N_ r$记录$S_ r&rsquo;$中在这一轮中的平均值大于arm1的arm的数量，有：
$$\mathbb{E}[N_ r]\leq\sum_ {i \in S_ r&rsquo;} \exp(-\frac{1}{2}\frac{B\Delta^2_ i}{|S_ r|\log(n)})\leq |S_ r&rsquo;|\exp(-\frac{1}{8}\frac{B\Delta^2_ {n_ r}}{n_ r \log(n)}) $$
接着用Markov Inequality:
$$Pr[N_ r&gt;\frac{1}{3}|S_ r&rsquo;|]\leq 3 \exp(-\frac{1}{8}\frac{B\Delta^2_ {n_ r}}{n_ r \log(n)})$$
也就是说，有很高概率并没有那么多不那么好的机器的empirical mean比最好的机器的empirical mean大。</p>
<p>最后，因为只有在后3/4中有至少1/3比arm 1大的时候，arm 1才有可能被淘汰，所以说arm 1在任意一轮被淘汰的概率最多是：
$$3 \sum_ {r=1}^{\log n} \exp(-\frac{1}{8}\frac{B\Delta^2_ {n_ r}}{n_ r \log(n)})\leq 3 \log(n) \exp(-\frac{B}{8 H_ 2 \log(n)})$$
这等价于
$$B = \Omega\left(H_ 2 \log n \log\left(\frac{\log n}{\delta}\right)\right)$$</p>
<h3 id="application-to-hyperparameter-tuning">Application to HyperParameter Tuning<a hidden class="anchor" aria-hidden="true" href="#application-to-hyperparameter-tuning">#</a></h3>
<p>在超参选择上，每一个超参的set都是一个arm，在初始阶段，我们随机选择许多配置。</p>
<p>在setting上不太一样的点是：</p>
<ul>
<li>
<p><strong>假设</strong>：可以观察到中间结果，能够在训练中途终止一些配置。</p>
</li>
<li>
<p><strong>操作</strong>：在训练过程中移除较不具前景的超参对应的实验。</p>
</li>
</ul>
<p>另一不一样的点是，我们并不是直接从随机变量中抽取样本，而是可以通过付出一定的代价来获得更加准确的观测值，这个代价就是更久的观察时间。最后观测到的值作为返回值。</p>
<p><img loading="lazy" src="../img/ml5/image13.png#center"></p>
<p>也就是说对于所有 $i \in [n], k \geq 1$，令 $\ell_ {i,k} \in \mathbb{R}$ 为臂 $i$ 的一个序列，假设：
$$
v_ i = \lim_ {\tau \to \infty} \ell_ {i,\tau} \quad \text{存在}
$$
那么对应的投入更多的budget就是对于运行更多的epoch数。</p>
<p><img loading="lazy" src="../img/ml5/image14.png#center">
一个实际运行的例子：
<img loading="lazy" src="../img/ml5/image15.png#center"></p>
<p>那么在这样的setting下有没有理论的保证呢？</p>
<p>我们首先引入一些记号：</p>
<ul>
<li>$\gamma_ i (t)$: 关于$t$单调不增，它给出了每个 $t$ 对应的最小值，使得：
$$|\ell_ {i,t} - v_ i| \leq \gamma_ i(t)$$
也就是说它是曲线的“包络线”，表示当前观测值距离极限$v_ i$的接近程度。</li>
<li>$\gamma_ i^{-1}(\alpha) = \min{t \in \mathbb{N}: \gamma_ i(t) \leq \alpha}$
表示首次进入与 $v_ i$ 的 $\alpha$-邻域的时间点,值得注意的是，这里我们假设一旦我们进入，我们就再也不会出去了。</li>
</ul>
<p>如果 $ k_ i \geq \gamma_ i^{-1}\left(\frac{v_ i - v_ 1}{2}\right) $ 且 $ k_ 1 \geq \gamma_ 1^{-1}\left(\frac{v_ i - v_ 1}{2}\right) $，则臂 $ i $ 和臂 $ 1 $ 可以被分开（即区分出优劣)。</p>
<blockquote>
<p><strong>Theorem</strong>：<br>
令 $\bar{\gamma}(t) = \max_ i \gamma_ i(t)$，则有：$$B \geq 2 \log_ 2(n) \left( n + \sum_ {i=2,\dots,n} \bar{\gamma}^{-1}\left(\frac{v_ i - v_ 1}{2}\right) \right)$$
在以上条件下，SH算法能够返回最佳臂。</p>
</blockquote>
<p>证明如下：</p>
<p>注意到：
$$
B&rsquo; = 2 \left( n + \sum_ {i=2,\dots,n} \bar{\gamma}^{-1} \left( \frac{v_ i - v_ 1}{2} \right) \right)
$$</p>
<p>每个臂被拉的次数为：$\frac{B&rsquo;}{|S_ r|}$,其中：
$$
\frac{B&rsquo;}{|S_ r|} &gt; \bar{\gamma}^{-1} \left( \frac{v_ {\lfloor\frac{|S_ r|}{2}\rfloor+1} - v_ 1}{2} \right)
$$
这个结论是初等数学结论，读者不难自证。</p>
<p>如果：
$$
k_ i \geq \gamma_ i^{-1} \left( \frac{v_ i - v_ 1}{2} \right), \quad k_ 1 \geq \gamma_ 1^{-1} \left( \frac{v_ i - v_ 1}{2} \right)
$$
那么臂 $i$ 和臂 $1$ 可以被区分开。</p>
<p>因此，在第 $k$ 轮中，我们知道臂 $\lfloor |S_ r| / 2 \rfloor + 1$ 和臂 $1$ 已经被区分开。</p>
<p>所以我们在$S_ {\log_ 2(n)}$轮中就能够辨认最佳臂1了。</p>
<h2 id="neural-architecture-search">Neural Architecture Search<a hidden class="anchor" aria-hidden="true" href="#neural-architecture-search">#</a></h2>
<p><img loading="lazy" src="../img/ml5/image16.png#center"></p>
<p>这里的任务是Given a specific task. Find the best network structure for this task.</p>
<p>一些成功的工作包括：</p>
<ul>
<li>强化学习</li>
</ul>
<p><img loading="lazy" src="../img/ml5/image17.png#center"></p>
<p><img loading="lazy" src="../img/ml5/image18.png#center"></p>
<ul>
<li>随机搜索</li>
</ul>
<p><img loading="lazy" src="../img/ml5/image19.png#center"></p>
<ul>
<li><strong>传统NAS算法</strong>需要大量的GPU计算资源。</li>
<li>通常只能用于一些代理任务（小规模/辅助任务）：
<ul>
<li>在小型数据集上训练。</li>
<li>使用少量的神经网络模块（blocks），仅训练几个epoch。</li>
<li>计算代价较低，但扩展到大规模任务时效果有限。</li>
</ul>
</li>
</ul>
<h3 id="proxyless-nas">ProxyLess NAS<a hidden class="anchor" aria-hidden="true" href="#proxyless-nas">#</a></h3>
<p>我们希望找到一个算法，使其能够适用于更大的任务。因此引入ProxylessNAS。</p>
<p><img loading="lazy" src="../img/ml5/image20.png#center"></p>
<p><strong>方法</strong>：</p>
<ul>
<li>对于每一层（或边），考虑所有可能的结构</li>
<li>定义 $N$ 个组件 $o_ i$（例如不同的卷积滤波器大小、Identity层、池化层等）</li>
<li><strong>联合训练结构（layer被选择的概率）与权重（内部的权重和偏置）</strong></li>
</ul>
<p>对于模型输出的类型，有如下三种方法：</p>
<ol>
<li>
<p><strong>One-shot方法</strong>（Bender et al., 2018）：</p>
<ul>
<li>输出为所有组件的加权和：
$$
\sum_ {i=1}^N o_ i(x)
$$</li>
<li><strong>性能不足</strong>。</li>
</ul>
</li>
<li>
<p><strong>DARTS方法</strong>（Liu et al., 2018）：</p>
<ul>
<li>使用权重 $ \alpha_ i $ 定义输出：
$$
\sum_ {i=1}^N p_ i o_ i(x), \quad p_ i = \frac{e^{\alpha_ i}}{\sum_ {j=1}^N e^{\alpha_ j}}
$$</li>
<li><strong>缺点</strong>：内存效率低，因为需要存储所有$N$条路径。最终模型只包含一条路径。</li>
</ul>
</li>
<li>
<p><strong>ProxylessNAS方法</strong>：</p>
<ul>
<li>二值化路径，定义布尔变量 $g$（一个one-hot向量）：
$$
g =
\begin{cases}
[1, 0, \dots, 0], &amp; \text{概率为 } p_ 1 \
\vdots \
[0, 0, \dots, 1], &amp; \text{概率为 } p_ N
\end{cases}
$$</li>
<li>输出依赖于单一路径：
$$
\sum_ {i=1}^N g_ i o_ i(x) =
\begin{cases}
o_ 1(x), &amp; \text{概率为 } p_ 1 \
\vdots \
o_ N(x), &amp; \text{概率为 } p_ N
\end{cases}
$$
注：这里的$p_ {[1:N]}$是根据$\alpha_ {[1:n]}$通过softmax采样得到的。</li>
<li><strong>优势</strong>：大幅节省内存。只需存储单一路径，而不存储所有 (N) 条路径。</li>
</ul>
</li>
</ol>
<p>最后看一下训练过程：</p>
<ol>
<li>
<p>交替训练网络结构和权重：</p>
<ul>
<li>在训练权重时，冻结 $ \alpha_ i $，并采样结构。</li>
<li>在训练 $ \alpha_ i $ 时，冻结权重。</li>
</ul>
</li>
<li>
<p>如何学习 $\alpha_ i$：</p>
<ul>
<li>链式法则近似计算 $ \frac{\partial L}{\partial \alpha_ i} $：
$$
\frac{\partial L}{\partial \alpha_ i} = \sum_ {j=1}^N \frac{\partial L}{\partial g_ j} \frac{\partial g_ j}{\partial \alpha_ i} \approx \sum_ {j=1}^N \frac{\partial L}{\partial g_ j} \frac{\partial p_ j}{\partial \alpha_ i}
$$</li>
<li>其中：
$$
\frac{\partial p_ j}{\partial \alpha_ i} = \sum_ {j=1}^N \delta_ {ij} p_ j (1 - p_ i) - p_ i p_ j
$$
$ \delta_ {ij} = 1 $ 如果 $ i = j $，否则为0。
更多的细节可以看一下<a href="https://arxiv.org/pdf/1812.00332">原论文</a>。</li>
</ul>
</li>
</ol>
<h2 id="misc">Misc<a hidden class="anchor" aria-hidden="true" href="#misc">#</a></h2>
<p>2025年了，祝大家新年快乐！</p>
<p>至于认识我的朋友，解释下为什么今年没有发朋友圈，因为实在是没有太多值得说的东西，有很多under-construction的事情，所以，2025对我、也希望对大家，会是很让人兴奋的一年。
<img loading="lazy" src="../img/ml5/image21.png#center">
调超参是一个听起来很有趣但实际上大家都在做Graduate Student Search的领域，也希望在做AI相关领域科研的朋友能够在2025年有“金手指”，调参手到擒来！</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:55186/blog/tags/machine-learning/">Machine-Learning</a></li>
      <li><a href="http://localhost:55186/blog/tags/computer-science/">Computer-Science</a></li>
      <li><a href="http://localhost:55186/blog/tags/optimization/">Optimization</a></li>
      <li><a href="http://localhost:55186/blog/tags/math/">Math</a></li>
      <li><a href="http://localhost:55186/blog/tags/artificial-intelligence/">Artificial-Intelligence</a></li>
      <li><a href="http://localhost:55186/blog/tags/algorithm/">Algorithm</a></li>
      <li><a href="http://localhost:55186/blog/tags/random-process/">Random-Process</a></li>
      <li><a href="http://localhost:55186/blog/tags/multi-arm-bandit/">Multi-Arm-Bandit</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:55186/blog/posts/condapack/">
    <span class="title">« Prev</span>
    <br>
    <span>Life Hacks Series: 1. How to manage your Python Environment</span>
  </a>
  <a class="next" href="http://localhost:55186/blog/posts/ml4/">
    <span class="title">Next »</span>
    <br>
    <span>Machine Learning Series: 4.Robust Machine Learning</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Machine Learning Series: 5.Hyperparameter Selection on x"
            href="https://x.com/intent/tweet/?text=Machine%20Learning%20Series%3a%205.Hyperparameter%20Selection&amp;url=http%3a%2f%2flocalhost%3a55186%2fblog%2fposts%2fml5%2f&amp;hashtags=machine-learning%2ccomputer-science%2coptimization%2cmath%2cartificial-intelligence%2calgorithm%2crandom-process%2cmulti-arm-bandit">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Machine Learning Series: 5.Hyperparameter Selection on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a55186%2fblog%2fposts%2fml5%2f&amp;title=Machine%20Learning%20Series%3a%205.Hyperparameter%20Selection&amp;summary=Machine%20Learning%20Series%3a%205.Hyperparameter%20Selection&amp;source=http%3a%2f%2flocalhost%3a55186%2fblog%2fposts%2fml5%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Machine Learning Series: 5.Hyperparameter Selection on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a55186%2fblog%2fposts%2fml5%2f&title=Machine%20Learning%20Series%3a%205.Hyperparameter%20Selection">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Machine Learning Series: 5.Hyperparameter Selection on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a55186%2fblog%2fposts%2fml5%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Machine Learning Series: 5.Hyperparameter Selection on whatsapp"
            href="https://api.whatsapp.com/send?text=Machine%20Learning%20Series%3a%205.Hyperparameter%20Selection%20-%20http%3a%2f%2flocalhost%3a55186%2fblog%2fposts%2fml5%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Machine Learning Series: 5.Hyperparameter Selection on telegram"
            href="https://telegram.me/share/url?text=Machine%20Learning%20Series%3a%205.Hyperparameter%20Selection&amp;url=http%3a%2f%2flocalhost%3a55186%2fblog%2fposts%2fml5%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Machine Learning Series: 5.Hyperparameter Selection on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Machine%20Learning%20Series%3a%205.Hyperparameter%20Selection&u=http%3a%2f%2flocalhost%3a55186%2fblog%2fposts%2fml5%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:55186/blog/">Nemo&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    <div class="busuanzi-footer">
        <span id="busuanzi_container_site_pv">
            Total site visits: <span id="busuanzi_value_site_pv"></span> times
        </span>
        
    </div></footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
