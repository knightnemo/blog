<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Nemo&#39;s Blog</title>
    <link>http://localhost:1313/blog/</link>
    <description>Recent content on Nemo&#39;s Blog</description>
    <generator>Hugo -- 0.140.2</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Machine Learning Series: 2.Unsupervised Learning(I)</title>
      <link>http://localhost:1313/blog/posts/ml2/</link>
      <pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/ml2/</guid>
      <description>This is the second article in the Machine Learning Series. It covers the first part of unsupervised learning, including topics like Dimension Reduction, PCA, k-NN, LSH and Metric Learning.</description>
    </item>
    <item>
      <title>Machine Learning Series: 3.Unsupervised Learning(II)</title>
      <link>http://localhost:1313/blog/posts/ml3/</link>
      <pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/ml3/</guid>
      <description>This is the third article in the Machine Learning Series. It covers the second part of unsupervised learning, including topics like Clustering, Spectral Graph Clustering, SimCLR, SNE and t-SNE.</description>
    </item>
    <item>
      <title>Machine Learning Series: 1.Optimization, Generalization and Supervised Learning</title>
      <link>http://localhost:1313/blog/posts/ml1/</link>
      <pubDate>Sat, 09 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/ml1/</guid>
      <description>This is the first article in the Machine Learning Series. It covers the basics of optimization(GD,SGD,SVRG,Mirror Descent,Linear Coupling), generalization(No Free Lunch, PAC Learning, VC Dimension), and supervised learning(Linear Regression, Logistic Regression, Compressed Sensing).</description>
    </item>
    <item>
      <title>复变笔记及其在静电场的应用</title>
      <link>http://localhost:1313/blog/posts/blogpost/</link>
      <pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/blogpost/</guid>
      <description>&lt;p&gt;之前忘记传复变的笔记了。现在补一下，链接如下：&lt;code&gt;https://cloud.tsinghua.edu.cn/f/0e002cc2dca948b7824d/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Credits: Lectures by 姚国武，24春季学期。&lt;/p&gt;
&lt;p&gt;至于为什么突然想到了，主要是因为General Physics讲到了复势，然后讲的可以说是不敢恭维，遂补充之。&lt;/p&gt;
&lt;h2 id=&#34;动机&#34;&gt;动机&lt;/h2&gt;
&lt;p&gt;首先，引入复变函数来描述电场和电势的动机是单纯的。 &lt;strong&gt;在我们已知电荷分布的情况下，通过电荷的积分就可以获得空间每一良定义的点的电势和电场&lt;/strong&gt; ：
$$ \phi(1)=\int_{all space}\frac{\rho(2) dV_2}{4\pi \epsilon_0 r_{12}} $$
$$E=-\nabla \phi$$
或者写成多级展开的形式：
$$\phi(\mathbf{r}) = \frac{1}{4\pi \epsilon_0} \sum_{n=0}^{\infty} \frac{1}{r^{n+1}} \int (r&amp;rsquo;)^n P_n(\cos\alpha) \rho(r&amp;rsquo;) , d\tau&#39;
$$
&lt;strong&gt;但问题是很多时候我们不知道全空间明确的电荷分布&lt;/strong&gt; ，比如有导体或者insulator的情况，我们不直接知道电荷在其中的分布，但是会有一些边界条件(Boundary Condition)，比如说导体构成一个等势体之类的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Uniqueness Theorem&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在体积 $V$ 内，对于已知的电荷分布 $\rho(\mathbf{x})$，如果在 $V$ 的封闭边界面 $S$ 上：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;给定电势 $\phi|_S$ （Dirichlet 边界条件）&lt;/li&gt;
&lt;li&gt;或给定电势的法向导数 $\left.\frac{\partial \phi}{\partial n}\right|_S$ （Neumann 边界条件）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么体积 $V$ 内的电场是唯一确定的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里，一种很巧妙的方式是根据 &lt;strong&gt;Uniqueness theorem&lt;/strong&gt; 做 &lt;strong&gt;镜像电荷(Image Charge&lt;/strong&gt;)，即把做镜像电荷的区域之外的区域看成$V$，然后这部分的电荷分布没变，只要保证边界条件不变就有电场的等价性了。这从数学上和物理上都很有美感，但是并不是所有的情况都有明确的镜像电荷分布与之对应，所以我们也需要一些别的手段。&lt;/p&gt;
&lt;p&gt;注意到，其实我们需要解的问题的通用方法其实是解这样的一组方程:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Poisson方程
$$\nabla^2 \phi=-\frac{\rho}{\epsilon_0}$$&lt;/li&gt;
&lt;li&gt;边界条件
e.g. $$\phi|_S=0$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在一维,这是个ODE,很容易。 &lt;strong&gt;从二维开始,这变成了一个PDE，不好找解析解，很多时候只能求助于数值方法。&lt;/strong&gt; 所以，有性质好的函数满足这样的方程，无疑是一件好事。复变函数（准确来说全纯函数）就是这样一种特殊情况： &lt;strong&gt;二维情况下Poisson方程取$\nabla^2 \phi=0$。&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
